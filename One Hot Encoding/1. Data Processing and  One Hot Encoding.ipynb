{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD LEVEL ONE-HOT-ENCODING OF BENGALI TEXTS FROM SCRATCH :-\n",
    "# Copyright (c) 2018 Abdul Hasib Uddin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer # for counting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART-1: INDEXING :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total white listed characters = 80 \n",
      "List =\n",
      " ['অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ক্ষ', 'ঁ', 'ং', 'ঃ', '়', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ৄ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৗ', 'ৠ', 'ৢ', 'ৣ', 'ৰ', 'ৱ', '০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯']\n"
     ]
    }
   ],
   "source": [
    "white_list_of_characters = ['অ','আ','ই','ঈ','উ','ঊ','ঋ','এ','ঐ','ও','ঔ',\n",
    "                            'ক','খ','গ','ঘ','ঙ',\n",
    "                            'চ','ছ','জ','ঝ','ঞ',\n",
    "                            'ট','ঠ','ড','ঢ','ণ',\n",
    "                            'ত','থ','দ','ধ','ন',\n",
    "                            'প','ফ','ব','ভ','ম',\n",
    "                            'য','র','ল','শ','ষ',\n",
    "                            'স','হ','ড়','ঢ়','য়',\n",
    "                            'ৎ','ক্ষ','ঁ','ং','ঃ',\n",
    "                            '়','া','ি','ী','ু',\n",
    "                            'ূ','ৃ','ৄ','ে','ৈ',\n",
    "                            'ো','ৌ','্','ৗ','ৠ',\n",
    "                            'ৢ','ৣ','ৰ','ৱ',\n",
    "                            '০','১','২','৩','৪',\n",
    "                            '৫','৬','৭','৮','৯']\n",
    "\n",
    "print('Total white listed characters =',len(white_list_of_characters),'\\nList =\\n',white_list_of_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"tweet_5000_positive_negative_two_classes_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for indexing : 36.24737583779631 sec(s)\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "word_dictionary = {'':0} # empty string will be used for zero padding\n",
    "\n",
    "starting_time_of_indexing = timer()\n",
    "for line in open(dataset_filename,'r',encoding='utf8').readlines():\n",
    "    current_word = \"\"\n",
    "    current_data = []\n",
    "    \n",
    "    for character in line:\n",
    "        if character not in white_list_of_characters:\n",
    "            if current_word not in word_dictionary.keys():\n",
    "                word_dictionary[current_word] = len(word_dictionary.keys())\n",
    "            for word,index_of_word in word_dictionary.items():\n",
    "                if word == current_word and current_word != \"\":\n",
    "                    current_data.append(index_of_word)\n",
    "                    break\n",
    "            current_word = \"\"\n",
    "        else:\n",
    "            current_word += character\n",
    "            \n",
    "    dataset.append(current_data)\n",
    "    \n",
    "elasped_time_for_indexing = timer() - starting_time_of_indexing\n",
    "print('Time elapsed for indexing :', elasped_time_for_indexing, 'sec(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of unique words = 10007\n",
      "No. of data in dataset = 3719\n",
      "\n",
      "\n",
      "Type of dataset = <class 'list'>\n",
      "Type of data in dataset = <class 'list'>\n",
      "Type of word in a data = <class 'int'>\n",
      "\n",
      "\n",
      "Length of the longest data in the dataset = 56\n",
      "Lengh of the shortest data in the dataset = 1\n",
      "\n",
      "\n",
      "Representations for data 2305 :\n",
      "[2362, 2363, 2364, 2365, 2366, 337, 2055, 1720, 2367, 2368, 24, 1585, 336, 259, 1720, 1720, 2367, 1981, 2369, 24, 1585, 336, 1114, 2370, 1720, 2367, 1190, 2369, 24, 1585, 336, 27, 2371, 2372, 2373, 335, 296, 1720, 2367, 2374, 24, 2375, 27, 2376, 2377, 2372, 259, 336, 1969, 2168, 1720, 2367, 447, 24, 1585, 336]\n",
      "৩৮ তম বিসিএস পরিক্ষার সময়সূচী ১ ৮ ৯ ২০১৮ ইংরেজি সকাল ১০ টা ২ ৯ ৯ ২০১৮ বাংলাদেশ বিষয়াবলী সকাল ১০ টা ৩ ১১ ৯ ২০১৮ আন্তর্জাতিক বিষয়াবলী সকাল ১০ টা এবং গনিত দুপুর ২টা ৪ ১২ ৯ ২০১৮ বিজ্ঞান সকাল ১০টা এবং মানসিক দক্ষতা দুপুর ২ টা ৫ ১৩ ৯ ২০১৮ বাংলা সকাল ১০ টা \n"
     ]
    }
   ],
   "source": [
    "print('No. of unique words =', len(word_dictionary))\n",
    "print('No. of data in dataset =', len(dataset))\n",
    "#print(word_dictionary)\n",
    "print('\\n')\n",
    "print('Type of dataset =',type(dataset))\n",
    "print('Type of data in dataset =',type(dataset[0]))\n",
    "print('Type of word in a data =',type(dataset[0][0]))\n",
    "print('\\n')\n",
    "print('Length of the longest data in the dataset =', len(max(dataset, key=len)))\n",
    "print('Lengh of the shortest data in the dataset =', len(min(dataset, key=len)))\n",
    "print('\\n')\n",
    "\n",
    "#data_no = 10\n",
    "#data_no = 207\n",
    "#data_no = 889\n",
    "data_no = 2305\n",
    "print('Representations for data', data_no, ':')\n",
    "print(dataset[data_no])\n",
    "msg = \"\"\n",
    "for value in dataset[data_no]:\n",
    "    for word,index_of_word in word_dictionary.items():\n",
    "        if value == index_of_word:\n",
    "            msg += word+\" \"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filename = \"tweet_5000_positive_negative_two_classes_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "label_dictionary = {}\n",
    "\n",
    "for current_label in open(labels_filename,'r',encoding='utf8').readlines():\n",
    "    if current_label not in label_dictionary.keys() and current_label != '':\n",
    "        label_dictionary[current_label] = len(label_dictionary.keys())\n",
    "    for label,index_of_label in label_dictionary.items():\n",
    "        if label == current_label:\n",
    "            labels.append(index_of_label)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classes = 3\n",
      "No. of labels in dataset = 3719\n",
      "{'positive\\n': 0, 'depressive\\n': 1, 'sim_negative\\n': 2}\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "0\n",
      "positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('No. of classes =', len(label_dictionary))\n",
    "print('No. of labels in dataset =', len(labels))\n",
    "print(label_dictionary)\n",
    "\n",
    "print(type(labels))\n",
    "print(type(labels[0]))\n",
    "\n",
    "data_no = -1\n",
    "print(labels[data_no])\n",
    "for label, index_of_label in label_dictionary.items():\n",
    "    if labels[data_no] == index_of_label:\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART-2: REMOVING MULTIPLE OCCURENCES OF DATA FROM DATASET AND CORRESPONDING LABELS :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = []\n",
    "filtered_labels = []\n",
    "for data,label in zip(dataset,labels):\n",
    "    if data not in filtered_dataset: # ignore duplicate data\n",
    "        filtered_dataset.append(data)\n",
    "        filtered_labels.append(label)\n",
    "        \n",
    "dataset = filtered_dataset\n",
    "labels = filtered_labels\n",
    "del(filtered_dataset)\n",
    "del(filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of unique data in dataset = 1624\n",
      "No. of labels = 1624\n",
      "Length of the longest data in dataset = 56\n",
      "Lengh of the shortest data in dataset = 1\n"
     ]
    }
   ],
   "source": [
    "print('No. of unique data in dataset =', len(dataset))\n",
    "print('No. of labels =', len(labels))\n",
    "\n",
    "print('Length of the longest data in dataset =', len(max(dataset, key=len)))\n",
    "print('Lengh of the shortest data in dataset =', len(min(dataset, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART-3: 0 (ZERO) PADDING :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "length_of_longest_data = len(max(dataset, key=len))\n",
    "print(length_of_longest_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_index in range(len(dataset)):\n",
    "    if len(dataset[data_index]) < length_of_longest_data: # if padding needed...\n",
    "        zero_padding_counter = length_of_longest_data - len(dataset[data_index]) # how many padding needed\n",
    "        #print(length_of_longest_data,'-',len(dataset[data_index]),'=',zero_padding_counter)\n",
    "        for padding in range(zero_padding_counter):\n",
    "            dataset[data_index].append(0) # padding one hot encoded dataset with list of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After zero padding :\n",
      "Size of dataset = 1624\n",
      "Size of a data in dataset (same for every data) = 56\n",
      "\n",
      "\n",
      "Length of the longest data in dataset = 56\n",
      "Lengh of the shortest data in dataset = 56\n",
      "Representations for data 1001 :\n",
      "[5973, 731, 152, 7207, 1370, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ধরি বাস না ছুঁই পানি                                                    \n"
     ]
    }
   ],
   "source": [
    "print('After zero padding :')\n",
    "print('Size of dataset =',len(dataset))\n",
    "print('Size of a data in dataset (same for every data) =',len(dataset[0])) # variable length\n",
    "print('\\n')\n",
    "print('Length of the longest data in dataset =', len(max(dataset, key=len)))\n",
    "print('Lengh of the shortest data in dataset =', len(min(dataset, key=len)))\n",
    "\n",
    "data_no = 1001\n",
    "print('Representations for data', data_no, ':')\n",
    "print(dataset[data_no])\n",
    "msg = \"\"\n",
    "for value in dataset[data_no]:\n",
    "    for word,index_of_word in word_dictionary.items():\n",
    "        if value == index_of_word:\n",
    "            msg += word+\" \"\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART-4: ONE-HOT-ENCODING :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10007\n"
     ]
    }
   ],
   "source": [
    "no_of_unique_words = len(word_dictionary.keys())\n",
    "print(no_of_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for one hot encoding = 184.54476180221386\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_dataset = []\n",
    "\n",
    "starting_time_of_encoding = timer()\n",
    "for data in dataset:\n",
    "    one_hot_encoded_data = []\n",
    "    for index_of_word in data:\n",
    "        one_hot_encoded_word = []\n",
    "        for index_of_one_hot_encoded_word in range(no_of_unique_words):\n",
    "            if index_of_one_hot_encoded_word == index_of_word:\n",
    "                one_hot_encoded_word.append(1)\n",
    "            else:\n",
    "                one_hot_encoded_word.append(0)\n",
    "        one_hot_encoded_data.append(one_hot_encoded_word)\n",
    "    one_hot_encoded_dataset.append(one_hot_encoded_data)\n",
    "    \n",
    "elapsed_time_for_encoding = timer() - starting_time_of_encoding\n",
    "print('Time elapsed for one hot encoding =', elapsed_time_for_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of one hot encoded dataset = <class 'list'>\n",
      "Type of a data in one hot encoded dataset = <class 'list'>\n",
      "Type of a word in a one hot encoded data = <class 'list'>\n",
      "Type of a element in a one hot encoded word = <class 'int'>\n",
      "\n",
      "\n",
      "Size of one hot encoded dataset = 1624\n",
      "Length of the longest data in one hot encoded dataset = 56\n",
      "Lengh of the shortest data in one hot encoded dataset = 56\n",
      "Size of a word in a one hot encoded data = 10007\n",
      "\n",
      "\n",
      "[1, 2, 3, 4, 5, 6, 7, 3, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "সবথেকে বড় যুদ্ধ হলো নিজের মনের সাথে যুদ্ধ আবেগ                                                 \n",
      "\n",
      "One hot encoded word representation (a single word) upto 10 elemnts:\n",
      " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] ...\n"
     ]
    }
   ],
   "source": [
    "print('Type of one hot encoded dataset =',type(one_hot_encoded_dataset))\n",
    "print('Type of a data in one hot encoded dataset =',type(one_hot_encoded_dataset[0]))\n",
    "print('Type of a word in a one hot encoded data =',type(one_hot_encoded_dataset[0][0]))\n",
    "print('Type of a element in a one hot encoded word =',type(one_hot_encoded_dataset[0][0][0]))\n",
    "print('\\n')\n",
    "print('Size of one hot encoded dataset =',len(one_hot_encoded_dataset))\n",
    "print('Length of the longest data in one hot encoded dataset =', len(max(one_hot_encoded_dataset, key=len)))\n",
    "print('Lengh of the shortest data in one hot encoded dataset =', len(min(one_hot_encoded_dataset, key=len)))\n",
    "#print('Size of a data in one hot encoded dataset (depends upon no. of words in a data) =',len(one_hot_encoded_dataset[0])) # variable length\n",
    "print('Size of a word in a one hot encoded data =',len(one_hot_encoded_dataset[0][0]))\n",
    "print('\\n')\n",
    "\n",
    "data_no = 0\n",
    "print(dataset[data_no])\n",
    "msg = \"\"\n",
    "for value in dataset[data_no]:\n",
    "    for word,index_of_word in word_dictionary.items():\n",
    "        if value == index_of_word:\n",
    "            msg += word+\" \"\n",
    "print(msg,'\\n')\n",
    "print('One hot encoded word representation (a single word) upto 10 elemnts:\\n',one_hot_encoded_dataset[data_no][0][:10],'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "no_of_classes = len(label_dictionary.keys())\n",
    "print(no_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = []\n",
    "for index_of_label in labels:\n",
    "    current_one_hot_encoded_label = []\n",
    "    for index_of_one_hot_encoded_label in range(no_of_classes):\n",
    "        if index_of_one_hot_encoded_label == index_of_label:\n",
    "            current_one_hot_encoded_label.append(1)\n",
    "        else:\n",
    "            current_one_hot_encoded_label.append(0)\n",
    "    one_hot_encoded_labels.append(current_one_hot_encoded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of one hot encoded label set = <class 'list'>\n",
      "Type of a one hot encoded label in label set = <class 'list'>\n",
      "Type of an element in a one hot encoded label = <class 'int'>\n",
      "\n",
      "\n",
      "Size of one hot encoded label set = 1624\n",
      "Size of a one hot encoded label in label set = 3\n",
      "\n",
      "\n",
      "A one hot encoded label in label set : [1, 0, 0]\n",
      "An element in a one hot encoded label : 1\n",
      "\n",
      "\n",
      "{'positive\\n': 0, 'depressive\\n': 1, 'sim_negative\\n': 2}\n",
      "1\n",
      "depressive\n",
      "\n",
      "[0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Type of one hot encoded label set =',type(one_hot_encoded_labels))\n",
    "print('Type of a one hot encoded label in label set =',type(one_hot_encoded_labels[0]))\n",
    "print('Type of an element in a one hot encoded label =',type(one_hot_encoded_labels[0][0]))\n",
    "print('\\n')\n",
    "print('Size of one hot encoded label set =',len(one_hot_encoded_labels))\n",
    "print('Size of a one hot encoded label in label set =',len(one_hot_encoded_labels[0]))\n",
    "print('\\n')\n",
    "#print('One hot encoded label set :',one_hot_encoded_labels)\n",
    "print('A one hot encoded label in label set :',one_hot_encoded_labels[0])\n",
    "print('An element in a one hot encoded label :',one_hot_encoded_labels[0][0])\n",
    "print('\\n')\n",
    "\n",
    "data_no = -1\n",
    "print(label_dictionary)\n",
    "print(labels[data_no])\n",
    "for label, index_of_label in label_dictionary.items():\n",
    "    if labels[data_no] == index_of_label:\n",
    "        print(label)\n",
    "print(one_hot_encoded_labels[data_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
